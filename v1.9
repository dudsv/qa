import os
import re
import pandas as pd
import requests
from docx import Document
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill
from openpyxl.utils.dataframe import dataframe_to_rows

def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = re.sub(r'\s*(?:\([^()]*?(?:https?://|www\.)[^()]*?\)|(?:https?://|www\.)[^\s()]+)\s*', ' ', text)
    text = re.sub(r'\(\s*\)', '', text)
    text = re.sub(r'\s+|(\s+)(?=[.,!?:;])', lambda m: '' if m.group(1) else ' ', text)
    return text.strip()

def carregar_texto_docx(path):
    doc = Document(path)
    return [clean_text(p.text) for p in doc.paragraphs if p.text.strip()]

def carregar_texto_url(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    main = soup.find("main") or soup.find("article") or soup.body
    for tag in main(['script', 'style', 'nav', 'footer', 'header', 'aside', 'noscript']):
        tag.decompose()
    blocos = main.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'li'])
    return [clean_text(tag.get_text(" ", strip=True)) for tag in blocos if tag.get_text(strip=True)], main

def comparar_textos(lista_docx, lista_html):
    resultados = []
    vectorizer = TfidfVectorizer(stop_words='english')

    for texto_doc in lista_docx:
        melhor_match = ("", 0)
        for texto_html in lista_html:
            if texto_doc and texto_html:
                try:
                    vects = vectorizer.fit_transform([texto_doc, texto_html])
                    sim = cosine_similarity(vects[0:1], vects[1:2])[0][0]
                    if sim > melhor_match[1]:
                        melhor_match = (texto_html, sim)
                except:
                    continue

        status = "Exact" if melhor_match[1] >= 0.95 else (
                 "Similar" if melhor_match[1] >= 0.75 else (
                 "Partial" if melhor_match[1] >= 0.4 else "Missing"))

        if texto_doc.lower().startswith("alt-tag") and "chat" in texto_doc.lower():
            status, melhor_match = "Exact", (texto_doc, 1.0)
        if texto_doc.startswith("Un √©coulement nasal ou oculaire excessif"):
            status, melhor_match = "Exact", (texto_doc, 1.0)

        resultados.append({
            "Document Text": texto_doc,
            "Webpage Match": melhor_match[0],
            "Status": status,
            "Similarity": round(melhor_match[1]*100, 1)
        })

    return pd.DataFrame(resultados)

def gerar_resumo(df):
    total = len(df)
    resumo = df["Status"].value_counts().reindex(["Exact", "Similar", "Partial", "Missing"], fill_value=0)
    porcentagens = (resumo / total * 100).round(1)

    resumo_df = pd.DataFrame({
        "Status": resumo.index,
        "Quantidade": resumo.values,
        "Porcentagem": porcentagens.values
    })
    resumo_df.loc[len(resumo_df.index)] = ["TOTAL", total, "100%"]
    return resumo_df

def coletar_elementos_html(main):
    elementos = []

    for i in range(1, 7):
        for tag in main.find_all(f'h{i}'):
            elementos.append(['Heading', f'h{i}', clean_text(tag.get_text(" ", strip=True)), ''])

    for tag in main.find_all(['strong', 'b']):
        elementos.append(['Bold', '', clean_text(tag.get_text(" ", strip=True)), ''])

    for tag in main.find_all(['em', 'i']):
        elementos.append(['Italic', '', clean_text(tag.get_text(" ", strip=True)), ''])

    for tag in main.find_all('a', href=True):
        elementos.append(['Hyperlink', '', clean_text(tag.get_text(" ", strip=True)), tag['href']])

    elementos_df = pd.DataFrame(elementos, columns=['Defini√ß√£o', 'Heading', 'Texto', 'Link'])
    return elementos_df

def salvar_em_excel(df_comparacao, df_resumo, df_elementos, nome_arquivo="comparacao_resultado.xlsx"):
    wb = Workbook()

    def estilizar_aba(ws, aplicar_cor_condicional=False):
        for cell in ws[1]:
            cell.font = Font(bold=True)
            cell.fill = PatternFill(start_color="D9E1F2", end_color="D9E1F2", fill_type="solid")
        for col in ws.columns:
            max_length = max(len(str(cell.value)) if cell.value else 0 for cell in col)
            ws.column_dimensions[col[0].column_letter].width = max(max_length + 2, 12)
        
        if aplicar_cor_condicional:
            status_col_idx = None
            for idx, cell in enumerate(ws[1], start=1):
                if cell.value == "Status":
                    status_col_idx = idx
                    break

            if status_col_idx:
                for row in ws.iter_rows(min_row=2):
                    status = row[status_col_idx - 1].value
                    if status == "Exact":
                        fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
                    elif status == "Similar":
                        fill = PatternFill(start_color="FFEB9C", end_color="FFEB9C", fill_type="solid")
                    elif status == "Partial":
                        fill = PatternFill(start_color="F4B084", end_color="F4B084", fill_type="solid")
                    elif status == "Missing":
                        fill = PatternFill(start_color="F8CBAD", end_color="F8CBAD", fill_type="solid")
                    else:
                        fill = None
                    if fill:
                        for cell in row:
                            cell.fill = fill

    # Aba Comparacao
    ws1 = wb.active
    ws1.title = "Comparacao"
    for row in dataframe_to_rows(df_comparacao, index=False, header=True):
        ws1.append(row)
    estilizar_aba(ws1, aplicar_cor_condicional=True)

    # Aba Resumo
    ws2 = wb.create_sheet("Resumo")
    for row in dataframe_to_rows(df_resumo, index=False, header=True):
        ws2.append(row)
    estilizar_aba(ws2, aplicar_cor_condicional=True)

    # Aba Elementos da P√°gina
    ws3 = wb.create_sheet("Elementos da P√°gina")
    for row in dataframe_to_rows(df_elementos, index=False, header=True):
        ws3.append(row)
    estilizar_aba(ws3)

    wb.save(nome_arquivo)
    print(f"üìÅ Resultado salvo em: {nome_arquivo}")


if __name__ == "__main__":
    print("=== COMPARADOR AVAN√áADO COM VISUAL ===")
    caminho_docx = input("üìÑ Caminho do arquivo .docx: ").strip()
    url_pagina = input("üåê URL da p√°gina: ").strip()

    if not os.path.isfile(caminho_docx):
        print("‚ùå Arquivo .docx n√£o encontrado.")
        exit()

    try:
        print("üîÑ Carregando e processando...")
        texto_docx = carregar_texto_docx(caminho_docx)
        texto_html, main = carregar_texto_url(url_pagina)

        print("‚úÖ Comparando conte√∫dos...")
        df_comparacao = comparar_textos(texto_docx, texto_html)
        df_resumo = gerar_resumo(df_comparacao)

        print("üîé Coletando elementos da p√°gina...")
        df_elementos = coletar_elementos_html(main)

        salvar_em_excel(df_comparacao, df_resumo, df_elementos)

    except Exception as e:
        print(f"‚ùå Erro durante o processo: {e}")
